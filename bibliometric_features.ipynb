{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "os.environ['PATH'] = os.environ['PATH'] + \":/usr/java/jdk1.8.0_162/bin\"\n",
    "os.environ['PYSPARK_PYTHON'] = '/home/tozeng/anaconda3/bin/python'\n",
    "\n",
    "import findspark\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \\\n",
    "    \"--packages com.databricks:spark-xml_2.11:0.5.0 pyspark-shell\"\n",
    "findspark.init('/opt/cloudera/parcels/SPARK2/lib/spark2/')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "    appName('sloan-query').\\\n",
    "    config('spark.driver.memory', '20g').\\\n",
    "    config('spark.network.timeout', '600s').\\\n",
    "    config('spark.driver.maxResultSize', '10g').\\\n",
    "    config('spark.executor.memory', '15g').\\\n",
    "    config('spark.kryoserializer.buffer.max', '1g').\\\n",
    "    config('spark.cores.max', '50').\\\n",
    "    getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_energy_pi = spark.read.parquet('./sloan/dimension_energy_pi.parquet')\n",
    "authorship = spark.read.parquet('/user/lliang06/daniel-dimensions/authorship.parquet')\n",
    "potential_researchers = spark.read.parquet('./sloan/potential_researchers.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorship = spark.read.parquet('/user/lliang06/daniel-dimensions/authorship.parquet')\n",
    "citations = spark.read.parquet('/user/lliang06/daniel-dimensions/citations.parquet')\n",
    "datasets = spark.read.parquet('/user/lliang06/daniel-dimensions/datasets')\n",
    "clinical_trials = spark.read.parquet('/user/lliang06/daniel-dimensions/clinical_trials')\n",
    "grants = spark.read.parquet('/user/lliang06/daniel-dimensions/grants')\n",
    "grid = spark.read.parquet('/user/lliang06/daniel-dimensions/grid')\n",
    "patents = spark.read.parquet('/user/lliang06/daniel-dimensions/patents')\n",
    "policy_documents = spark.read.parquet('/user/lliang06/daniel-dimensions/policy_documents')\n",
    "publications = spark.read.parquet('/user/lliang06/daniel-dimensions/publications')\n",
    "reports = spark.read.parquet('/user/lliang06/daniel-dimensions/reports')\n",
    "researchers = spark.read.parquet('/user/lliang06/daniel-dimensions/researchers')\n",
    "source_titles = spark.read.parquet('/user/lliang06/daniel-dimensions/source_titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubid = pd.read_csv('./data/lda_pubid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubid_coauthor_count = spark.createDataFrame(pubid).\\\n",
    "    join(authorship, on = 'publication_id', how = 'inner').\\\n",
    "    groupby('publication_id').count().withColumnRenamed('count', 'coauthor_count').\\\n",
    "    toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubid_coauthor_count.to_csv('./data/pubid_coauthor_count.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_id</th>\n",
       "      <th>coauthor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pub.1000005399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pub.1000006638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pub.1000013239</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pub.1000014339</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pub.1000015633</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187427</th>\n",
       "      <td>pub.1147433638</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187428</th>\n",
       "      <td>pub.1147767156</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187429</th>\n",
       "      <td>pub.1147932716</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187430</th>\n",
       "      <td>pub.1148007290</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187431</th>\n",
       "      <td>pub.1148092441</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6187432 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         publication_id  coauthor_count\n",
       "0        pub.1000005399               1\n",
       "1        pub.1000006638               1\n",
       "2        pub.1000013239               3\n",
       "3        pub.1000014339               5\n",
       "4        pub.1000015633               6\n",
       "...                 ...             ...\n",
       "6187427  pub.1147433638               4\n",
       "6187428  pub.1147767156               3\n",
       "6187429  pub.1147932716               6\n",
       "6187430  pub.1148007290               6\n",
       "6187431  pub.1148092441               6\n",
       "\n",
       "[6187432 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubid_coauthor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/dup_ids.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "dimension_dict = {}\n",
    "dimension_dict['Award_number'] = []\n",
    "dimension_dict['PI'] = []\n",
    "dimension_dict['researcher_id'] = []\n",
    "p = re.compile(r'ur.\\d+.\\d+')\n",
    "\n",
    "for l in lines:\n",
    "    if 'Award_number' in l:\n",
    "        dimension_dict['Award_number'].append(l.split(' ')[-1][:-1])\n",
    "    if (len(l.split(' ')) <= 4) & ('Award_number' not in l) & (l is not '\\n') & ('combine' not in l) & ('Combine' not in l):\n",
    "        dimension_dict['PI'].append(l.split('\\t')[-1].split('\\n')[0])\n",
    "    if (('combine' in l) | ('Combine' in l)) & ('&' in l):\n",
    "        if 'combine' in l:\n",
    "            dimension_dict['researcher_id'].append(l.split('combine')[-1][:-1].split('&'))\n",
    "        elif 'Combine' in l:\n",
    "            dimension_dict['researcher_id'].append(l.split('Combine')[-1][:-1].split('&'))\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapping = {}\n",
    "for ids in dimension_dict['researcher_id']:\n",
    "    for id in ids:\n",
    "        if id.strip() != '':\n",
    "            id_mapping[id.strip()] = ids[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/energy_grants_Dimensions_wAbstract_cleanest.csv')[['PI', 'researcher_id', 'StartYear', 'EndYear']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearBefore'] = df['StartYear'] - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1956"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    select('researcher_id').\\\n",
    "    drop_duplicates().\\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2683"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e147dfae9096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"row_number\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindowSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'row_number'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'researcher_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \"\"\"\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hzhuang/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import row_number\n",
    "windowSpec  = Window.partitionBy(\"researcher_id\").orderBy(\"year\")\n",
    "\n",
    "researcher_academic_startyear = authorship.\\\n",
    "    join(df.select('researcher_id'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(publications.select(fn.col('id').alias('publication_id'), 'year'), how = 'inner', on = 'publication_id').\\\n",
    "    dropna().\\\n",
    "    withColumn(\"row_number\", fn.row_number().over(windowSpec)).\\\n",
    "    where(fn.col('row_number') == 1).\\\n",
    "    select('researcher_id', 'year').\\\n",
    "    drop_duplicates().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# researcher_academic_startyear.to_csv('./data/researcher_academic_startyear.csv', index = False)\n",
    "researcher_academic_startyear = pd.read_csv('./data/researcher_academic_startyear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_academic_startyear_df = spark.createDataFrame(researcher_academic_startyear).\\\n",
    "                                        join(df.select('researcher_id', 'YearBefore'), 'researcher_id', 'inner').\\\n",
    "                                        drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2506"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher_academic_startyear_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publication Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_idx_nopp = publications.where(fn.col('type') != 'preprint').select(fn.col('id').alias('publication_id'), 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_count = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    where(fn.col('year') <= fn.col('YearBefore')).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'publication_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_count_3Y = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'publication_count_3Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_count_5Y = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'publication_count_5Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_count_10Y = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'publication_count_10Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec  = Window.partitionBy(\"researcher_id\")\n",
    "\n",
    "researcher_annual = authorship.\\\n",
    "    join(df.select('researcher_id'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    select('researcher_id', 'year').drop_duplicates().\\\n",
    "    withColumn(\"min\", fn.min('year').over(windowSpec)).\\\n",
    "    withColumn(\"max\", fn.max('year').over(windowSpec)).\\\n",
    "    select('researcher_id', 'min', 'max').drop_duplicates().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_annual['min'] = researcher_annual['min'].astype(int)\n",
    "researcher_annual['max'] = researcher_annual['max'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "researcher_annual['YearBefore'] = researcher_annual.apply(lambda x: range(x['min'], x['max']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_annual = researcher_annual.drop(['min', 'max'], axis = 1).explode('YearBefore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_annual = researcher_annual.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_annual['YearBefore'] = researcher_annual['YearBefore'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "researcher_annual_df = spark.createDataFrame(researcher_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_count_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    where(fn.col('year') <= fn.col('YearBefore')).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'publication_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_count_3Y_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'publication_count_3Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_count_5Y_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'publication_count_5Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_count_10Y_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'publication_count_10Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation Received Count by Citing Paper Publication Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where(fn.col('citation_year') <= fn.col('YearBefore')).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_3Y = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('citation_year') <= fn.col('YearBefore')) & (fn.col('citation_year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_3Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_5Y = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('citation_year') <= fn.col('YearBefore')) & (fn.col('citation_year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_5Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_10Y = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('citation_year') <= fn.col('YearBefore')) & (fn.col('citation_year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_10Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where(fn.col('citation_year') <= fn.col('YearBefore')).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_3Y_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('citation_year') <= fn.col('YearBefore')) & (fn.col('citation_year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_3Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_5Y_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('citation_year') <= fn.col('YearBefore')) & (fn.col('citation_year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_5Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_10Y_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('citation_year') <= fn.col('YearBefore')) & (fn.col('citation_year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_10Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation Received Count by Cited Paper Publication Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_3YPub = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_3YPub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_5YPub = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_5YPub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_10YPub = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_10YPub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_3YPub_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_3YPub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_5YPub_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_5YPub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_10YPub_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_10YPub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation Received Count by Cited Paper Publication Year and by Citing Paper Citing Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_3YPubCite = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id'), fn.col('year').alias('citing_year')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') >= (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    where((fn.col('citing_year') <= fn.col('YearBefore')) & (fn.col('citing_year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_3YPubCite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_5YPubCite = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id'), fn.col('year').alias('citing_year')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') >= (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    where((fn.col('citing_year') <= fn.col('YearBefore')) & (fn.col('citing_year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_5YPubCite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_10YPubCite = authorship.\\\n",
    "    join(df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id'), fn.col('year').alias('citing_year')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') >= (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    where((fn.col('citing_year') <= fn.col('YearBefore')) & (fn.col('citing_year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_10YPubCite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_3YPubCite_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id'), fn.col('year').alias('citing_year')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') >= (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    where((fn.col('citing_year') <= fn.col('YearBefore')) & (fn.col('citing_year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_3YPubCite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_5YPubCite_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id'), fn.col('year').alias('citing_year')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') >= (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    where((fn.col('citing_year') <= fn.col('YearBefore')) & (fn.col('citing_year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_5YPubCite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_10YPubCite_annual = authorship.\\\n",
    "    join(researcher_annual_df.select('researcher_id', 'YearBefore'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(pub_idx_nopp, how = 'inner', on = 'publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    join(pub_idx_nopp.select(fn.col('publication_id').alias('citing_publication_id'), fn.col('year').alias('citing_year')), 'citing_publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') >= (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    where((fn.col('citing_year') <= fn.col('YearBefore')) & (fn.col('citing_year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'citation_count_10YPubCite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Number of Unique Co-Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_count = df.\\\n",
    "    select('researcher_id', 'YearBefore').\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    join(publications.select(fn.col('id').alias('publication_id'), 'year'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('year') <= fn.col('YearBefore')).\\\n",
    "    join(authorship.withColumnRenamed('researcher_id', 'coauthor_id'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('researcher_id') != fn.col('coauthor_id')).\\\n",
    "    select('researcher_id', 'coauthor_id', 'YearBefore').drop_duplicates().\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'coauthor_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_count3Y = df.\\\n",
    "    select('researcher_id', 'YearBefore').\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    join(publications.select(fn.col('id').alias('publication_id'), 'year'), 'publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    join(authorship.withColumnRenamed('researcher_id', 'coauthor_id'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('researcher_id') != fn.col('coauthor_id')).\\\n",
    "    select('researcher_id', 'coauthor_id', 'YearBefore').drop_duplicates().\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'coauthor_count3Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_count5Y = df.\\\n",
    "    select('researcher_id', 'YearBefore').\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    join(publications.select(fn.col('id').alias('publication_id'), 'year'), 'publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    join(authorship.withColumnRenamed('researcher_id', 'coauthor_id'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('researcher_id') != fn.col('coauthor_id')).\\\n",
    "    select('researcher_id', 'coauthor_id', 'YearBefore').drop_duplicates().\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'coauthor_count5Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_count10Y = df.\\\n",
    "    select('researcher_id', 'YearBefore').\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    join(publications.select(fn.col('id').alias('publication_id'), 'year'), 'publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    join(authorship.withColumnRenamed('researcher_id', 'coauthor_id'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('researcher_id') != fn.col('coauthor_id')).\\\n",
    "    select('researcher_id', 'coauthor_id', 'YearBefore').drop_duplicates().\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'coauthor_count10Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "researcher_bibliometrics = researcher_academic_startyear_df.\\\n",
    "    join(publication_count, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(publication_count_3Y, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(publication_count_5Y, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(publication_count_10Y, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_3Y, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_5Y, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_10Y, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_3YPub, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_5YPub, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_10YPub, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_3YPubCite, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_5YPubCite, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_10YPubCite, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(coauthor_count, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(coauthor_count3Y, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(coauthor_count5Y, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(coauthor_count10Y, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    fillna(0).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_bibliometrics.to_csv('./data/researcher_bibliometrics.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_count_annual = researcher_annual_df.\\\n",
    "    select('researcher_id', 'YearBefore').\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    join(publications.select(fn.col('id').alias('publication_id'), 'year'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('year') <= fn.col('YearBefore')).\\\n",
    "    join(authorship.withColumnRenamed('researcher_id', 'coauthor_id'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('researcher_id') != fn.col('coauthor_id')).\\\n",
    "    select('researcher_id', 'coauthor_id', 'YearBefore').drop_duplicates().\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'coauthor_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_count3Y_annual = researcher_annual_df.\\\n",
    "    select('researcher_id', 'YearBefore').\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    join(publications.select(fn.col('id').alias('publication_id'), 'year'), 'publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(3)))).\\\n",
    "    join(authorship.withColumnRenamed('researcher_id', 'coauthor_id'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('researcher_id') != fn.col('coauthor_id')).\\\n",
    "    select('researcher_id', 'coauthor_id', 'YearBefore').drop_duplicates().\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'coauthor_count3Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_count5Y_annual = researcher_annual_df.\\\n",
    "    select('researcher_id', 'YearBefore').\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    join(publications.select(fn.col('id').alias('publication_id'), 'year'), 'publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(5)))).\\\n",
    "    join(authorship.withColumnRenamed('researcher_id', 'coauthor_id'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('researcher_id') != fn.col('coauthor_id')).\\\n",
    "    select('researcher_id', 'coauthor_id', 'YearBefore').drop_duplicates().\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'coauthor_count5Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_count10Y_annual = researcher_annual_df.\\\n",
    "    select('researcher_id', 'YearBefore').\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    join(publications.select(fn.col('id').alias('publication_id'), 'year'), 'publication_id', 'inner').\\\n",
    "    where((fn.col('year') <= fn.col('YearBefore')) & (fn.col('year') > (fn.col('YearBefore') - fn.lit(10)))).\\\n",
    "    join(authorship.withColumnRenamed('researcher_id', 'coauthor_id'), 'publication_id', 'inner').\\\n",
    "    where(fn.col('researcher_id') != fn.col('coauthor_id')).\\\n",
    "    select('researcher_id', 'coauthor_id', 'YearBefore').drop_duplicates().\\\n",
    "    groupby('researcher_id', 'YearBefore').count().withColumnRenamed('count', 'coauthor_count10Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_bibliometrics_annual = researcher_annual_df.\\\n",
    "    join(publication_count_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(publication_count_3Y_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(publication_count_5Y_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(publication_count_10Y_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_3Y_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_5Y_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_10Y_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_3YPub_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_5YPub_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_10YPub_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_3YPubCite_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_5YPubCite_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(citation_count_10YPubCite_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(coauthor_count_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(coauthor_count3Y_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(coauthor_count5Y_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    join(coauthor_count10Y_annual, ['researcher_id', 'YearBefore'], 'left').\\\n",
    "    fillna(0).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_bibliometrics_annual.sort_values(by = ['researcher_id', 'YearBefore']).to_csv('./data/researcher_annual_bibliometrics.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
