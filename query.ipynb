{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "os.environ['PATH'] = os.environ['PATH'] + \":/usr/java/jdk1.8.0_162/bin\"\n",
    "os.environ['PYSPARK_PYTHON'] = '/home/tozeng/anaconda3/bin/python'\n",
    "\n",
    "import findspark\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \\\n",
    "    \"--packages com.databricks:spark-xml_2.11:0.5.0 pyspark-shell\"\n",
    "findspark.init('/opt/cloudera/parcels/SPARK2/lib/spark2/')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "    appName('query').\\\n",
    "    config('spark.driver.memory', '20g').\\\n",
    "    config('spark.network.timeout', '600s').\\\n",
    "    config('spark.driver.maxResultSize', '30g').\\\n",
    "    config('spark.executor.memory', '15g').\\\n",
    "    config('spark.kryoserializer.buffer.max', '1g').\\\n",
    "    config('spark.cores.max', '50').\\\n",
    "    config('spark.rpc.message.maxSize', '256').\\\n",
    "    getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lliang06/.local/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dimensions tables\n",
    "\n",
    "authorship = spark.read.parquet('/user/lliang06/daniel-dimensions/authorship.parquet')\n",
    "citations = spark.read.parquet('/user/lliang06/daniel-dimensions/citations.parquet')\n",
    "datasets = spark.read.parquet('/user/lliang06/daniel-dimensions/datasets')\n",
    "clinical_trials = spark.read.parquet('/user/lliang06/daniel-dimensions/clinical_trials')\n",
    "grants = spark.read.parquet('/user/lliang06/daniel-dimensions/grants')\n",
    "grid = spark.read.parquet('/user/lliang06/daniel-dimensions/grid')\n",
    "patents = spark.read.parquet('/user/lliang06/daniel-dimensions/patents')\n",
    "policy_documents = spark.read.parquet('/user/lliang06/daniel-dimensions/policy_documents')\n",
    "publications = spark.read.parquet('/user/lliang06/daniel-dimensions/publications')\n",
    "reports = spark.read.parquet('/user/lliang06/daniel-dimensions/reports')\n",
    "researchers = spark.read.parquet('/user/lliang06/daniel-dimensions/researchers')\n",
    "dimension_energy_pi = spark.read.parquet('./sloan/dimension_energy_pi.parquet')\n",
    "authorship = spark.read.parquet('/user/lliang06/daniel-dimensions/authorship.parquet')\n",
    "potential_researchers = spark.read.parquet('./sloan/potential_researchers.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Dimensions ID for funded researchers\n",
    "\n",
    "dimension_df = pd.read_excel('./data/Dimensions_ID_final.xlsx')\n",
    "\n",
    "with open('./data/dup_ids.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "dimension_dict = {}\n",
    "dimension_dict['Award_number'] = []\n",
    "dimension_dict['PI'] = []\n",
    "dimension_dict['researcher_id'] = []\n",
    "p = re.compile(r'ur.\\d+.\\d+')\n",
    "\n",
    "for l in lines:\n",
    "    if 'Award_number' in l:\n",
    "        dimension_dict['Award_number'].append(l.split(' ')[-1][:-1])\n",
    "    if (len(l.split(' ')) <= 4) & ('Award_number' not in l) & (l is not '\\n') & ('combine' not in l) & ('Combine' not in l):\n",
    "        dimension_dict['PI'].append(l.split('\\t')[-1].split('\\n')[0])\n",
    "    if (('combine' in l) | ('Combine' in l)) & ('&' in l):\n",
    "        if 'combine' in l:\n",
    "            dimension_dict['researcher_id'].append(l.split('combine')[-1][:-1].split('&'))\n",
    "        elif 'Combine' in l:\n",
    "            dimension_dict['researcher_id'].append(l.split('Combine')[-1][:-1].split('&'))\n",
    "                    \n",
    "ids_match = pd.DataFrame(dimension_dict).explode('researcher_id')[['PI', 'researcher_id']].drop_duplicates()\n",
    "\n",
    "dimension_ids = pd.concat([dimension_df[dimension_df['researcher_id'] != '-999'], ids_match])\n",
    "\n",
    "# dimension_ids.to_csv('PI_dimension_ids.csv', index = False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_ids_df = spark.createDataFrame(pd.read_csv('./data/PI_dimension_ids.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting publications funded researchers authored\n",
    "\n",
    "authorship.\\\n",
    "    join(dimension_ids_df, 'researcher_id', 'inner').\\\n",
    "    join(publications.select(publications.id, publications.abstract.preferred.alias('abstract')).withColumnRenamed('id', 'publication_id'), 'publication_id', 'inner').\\\n",
    "    select('publication_id', 'abstract').dropna().drop_duplicates().write.parquet('./sloan/dimension_energy_pi.parquet', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_energy_pi = spark.read.parquet('./sloan/dimension_energy_pi.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors citing publications authored by funded researchers\n",
    "\n",
    "citing_authors = dimension_energy_pi.select('publication_id').\\\n",
    "    join(citations, 'publication_id', 'inner').\\\n",
    "    select(fn.col('citing_publication_id').alias('publication_id')).\\\n",
    "    join(authorship, 'publication_id', 'inner').\\\n",
    "    select('researcher_id')\n",
    "\n",
    "# citing_authors.write.parquet('./sloan/citing_authors.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors referenced by publications authored by funded researchers\n",
    "\n",
    "referenced_authors = dimension_energy_pi.select(fn.col('publication_id').alias('citing_publication_id')).\\\n",
    "    join(citations, 'citing_publication_id', 'inner').\\\n",
    "    join(authorship, 'publication_id', 'inner').\\\n",
    "    select('researcher_id')\n",
    "\n",
    "# referenced_authors.write.parquet('./sloan/referenced_authors.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researchers affiliated to US at some point of their career\n",
    "\n",
    "us_researchers = researchers.\\\n",
    "    where(fn.size(fn.col('research_orgs')) != 0).\\\n",
    "    select(fn.col('id').alias('researcher_id'), fn.explode('research_orgs').alias('grid_id')).\\\n",
    "    join(grid.select(grid.address.country.alias('country'), grid.id.alias('grid_id')), 'grid_id', 'inner').\\\n",
    "    where(fn.col('country') == 'United States').\\\n",
    "    select('researcher_id')\n",
    "\n",
    "# us_researchers.write.parquet('./sloan/us_researchers.parquet', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researchers currently affiliated with US\n",
    "\n",
    "current_us_researchers = researchers.\\\n",
    "    where(fn.size(fn.col('research_orgs')) != 0).\\\n",
    "    select(fn.col('id').alias('researcher_id'), fn.element_at('research_orgs', -1).alias('grid_id')).\\\n",
    "    join(grid.select(grid.address.country.alias('country'), grid.id.alias('grid_id')), 'grid_id', 'inner').\\\n",
    "    where(fn.col('country') == 'United States').\\\n",
    "    select('researcher_id').drop_duplicates()\n",
    "\n",
    "# current_us_researchers.write.parquet('./sloan/current_us_researchers.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researchers affiliated with not just US\n",
    "\n",
    "not_only_us_researchers = us_researchers.\\\n",
    "    join(researchers.select(fn.col('id').alias('researcher_id'), fn.col('research_orgs')), 'researcher_id', 'inner').\\\n",
    "    select('researcher_id', fn.explode('research_orgs').alias('grid_id')).\\\n",
    "    join(grid.select(grid.address.country.alias('country'), grid.id.alias('grid_id')), 'grid_id', 'inner').\\\n",
    "    where(fn.col('country') != 'United States').\\\n",
    "    select('researcher_id').drop_duplicates()\n",
    "\n",
    "# not_only_us_researchers.write.parquet('./sloan/not_only_us_researchers.parquet', mode= 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researchers who have at least 10 works\n",
    "\n",
    "ten_work = researchers.\\\n",
    "                select(fn.col('id').alias('researcher_id')).\\\n",
    "                join(authorship, 'researcher_id', 'inner').\\\n",
    "                groupby('researcher_id').count().\\\n",
    "                where(fn.col('count') >= 10).\\\n",
    "                join(researchers.select(fn.col('id').alias('researcher_id'), 'total_publications'), 'researcher_id', 'inner').\\\n",
    "                where(fn.col('total_publications') >= 10).\\\n",
    "                select('researcher_id').drop_duplicates()\n",
    "\n",
    "# ten_work.write.parquet('./sloan/ten_work.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researchers who have at least one work between 2009 and 2016\n",
    "\n",
    "active_researchers = publications.\\\n",
    "    where(fn.col('year') >= 2009).\\\n",
    "    where(fn.col('year') <= 2016).\\\n",
    "    select(fn.explode('researcher_ids').alias('researcher_id'), 'year').\\\n",
    "    groupby('researcher_id').\\\n",
    "    count().\\\n",
    "    where(fn.col('count') >= 1).\\\n",
    "    select('researcher_id')\n",
    "\n",
    "# active_researchers.write.parquet('./sloan/active_researchers.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citing_authors = spark.read.parquet('./sloan/citing_authors.parquet')\n",
    "referenced_authors = spark.read.parquet('./sloan/referenced_authors.parquet')\n",
    "us_researchers = spark.read.parquet('./sloan/us_researchers.parquet')\n",
    "not_only_us_researchers = spark.read.parquet('./sloan/not_only_us_researchers.parquet')\n",
    "ten_work = spark.read.parquet('./sloan/ten_work.parquet')\n",
    "active_researchers = spark.read.parquet('./sloan/active_researchers.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citing_authors.\\\n",
    "    union(referenced_authors).\\\n",
    "    join(dimension_ids_df, 'researcher_id', 'left_anti').\\ # remove funded researchers\n",
    "    join(us_researchers, 'researcher_id', 'inner').\\\n",
    "    join(not_only_us_researchers, 'researcher_id', 'left_anti').\\ # remove researchers who are not affiliated with US at any point of their career\n",
    "    join(ten_work, 'researcher_id', 'inner').\\\n",
    "    join(active_researchers, 'researcher_id', 'inner').\\\n",
    "    dropna().drop_duplicates().\\\n",
    "    write.parquet('./sloan/potential_researchers.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_researchers = spark.read.parquet('./sloan/potential_researchers.parquet')\n",
    "# all_PI_idx = pd.read_csv('./data/all_PI_idx.csv')\n",
    "# sampled_id = all_PI_idx[all_PI_idx['category'] != 'potential']['researcher_id'].unique()\n",
    "# spark.createDataFrame(pd.DataFrame(sampled_id).rename({0: 'researcher_id'}, axis = 1)).write.parquet('./sloan/sampled_id.parquet')\n",
    "sampled_id_df = spark.read.parquet('./sloan/sampled_id.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# granted_researchers = dimension_ids_df.select('researcher_id')\n",
    "\n",
    "# target_researchers = potential_researchers.select('researcher_id')s.\\\n",
    "#     union(granted_researchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+-------------+----+\n",
      "|publication_id|citing_publication_id|citation_year|year|\n",
      "+--------------+---------------------+-------------+----+\n",
      "|pub.1000000255|       pub.1001799494|         2014|2010|\n",
      "|pub.1000000255|       pub.1068979015|         2015|2010|\n",
      "|pub.1000000255|       pub.1141546631|         2021|2010|\n",
      "|pub.1000000255|       pub.1072255085|         2015|2010|\n",
      "|pub.1000000255|       pub.1147162789|         2022|2010|\n",
      "|pub.1000000255|       pub.1117736772|         2012|2010|\n",
      "|pub.1000000255|       pub.1044147342|         2015|2010|\n",
      "|pub.1000000255|       pub.1117737630|         2012|2010|\n",
      "|pub.1000000255|       pub.1022733763|         2016|2010|\n",
      "|pub.1000000255|       pub.1069052145|         2012|2010|\n",
      "|pub.1000000255|       pub.1100654402|         2018|2010|\n",
      "|pub.1000000255|       pub.1072255293|         2014|2010|\n",
      "|pub.1000000255|       pub.1106476923|         2018|2010|\n",
      "|pub.1000000255|       pub.1121181968|         2019|2010|\n",
      "|pub.1000000255|       pub.1008775128|         2016|2010|\n",
      "|pub.1000000255|       pub.1106456943|         2018|2010|\n",
      "|pub.1000000255|       pub.1136995745|         2021|2010|\n",
      "|pub.1000000255|       pub.1117742046|         2014|2010|\n",
      "|pub.1000000255|       pub.1138358298|         2021|2010|\n",
      "|pub.1000000255|       pub.1006968944|         2013|2010|\n",
      "+--------------+---------------------+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.\\\n",
    "    join(publications.withColumnRenamed('id', 'publication_id').select('publication_id', 'year'), on = 'publication_id', how ='inner').\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All abstracts for researcher matching\n",
    "\n",
    "potential_researchers.\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    join(dimension_energy_pi, 'publication_id', 'left_anti').\\\n",
    "    select('publication_id').drop_duplicates().\\\n",
    "    join(publications.select(publications.id, publications.abstract.preferred.alias('abstract')).withColumnRenamed('id', 'publication_id'), 'publication_id', 'inner').\\\n",
    "    dropna().repartition(1).write.parquet('./sloan/potential_abstracts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_researchers.sample(fraction = 0.01).\\\n",
    "    union(spark.createDataFrame(dimension_ids_df[['researcher_id']])).\\\n",
    "    write.parquet('./sloan/sampled_energy_PI.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_energy_PI.\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    select('publication_id').drop_duplicates().\\\n",
    "    join(publications.select(publications.id, publications.abstract.preferred.alias('abstract')).withColumnRenamed('id', 'publication_id'), 'publication_id', 'inner').\\\n",
    "    dropna().write.parquet('./sloan/sampled_energy_PI_abstracts.parquet', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_abstracts = spark.read.parquet('./sloan/potential_abstracts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[publication_id: string, abstract: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6036472"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_researchers.\\\n",
    "    join(authorship, 'researcher_id', 'inner').\\\n",
    "    select('publication_id').drop_duplicates().\\\n",
    "    join(publications.select(publications.id, publications.abstract.preferred.alias('abstract')).withColumnRenamed('id', 'publication_id'), 'publication_id', 'inner').\\\n",
    "    dropna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320454"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension_energy_pi.\\\n",
    "    select('publication_id').drop_duplicates().\\\n",
    "    join(publications.select(publications.id, publications.abstract.preferred.alias('abstract')).withColumnRenamed('id', 'publication_id'), 'publication_id', 'inner').\\\n",
    "    dropna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get which potential authors cites which funded researcher\n",
    "\n",
    "potential_author_citing = authorship.\\\n",
    "    join(dimension_ids_df.select('researcher_id'), on = 'researcher_id', how = 'inner').\\\n",
    "    join(citations.drop('citation_year'), on = 'publication_id', how = 'inner').\\\n",
    "    join(authorship.withColumnRenamed('publication_id', 'citing_publication_id').withColumnRenamed('researcher_id', 'citing_researcher_id'), on = 'citing_publication_id', how = 'inner').\\\n",
    "    select('researcher_id', 'citing_researcher_id').\\\n",
    "    withColumnRenamed('citing_researcher_id', 'related_researcher_id').\\\n",
    "    dropDuplicates().toPandas()\n",
    "\n",
    "potential_author_referenced = authorship.\\\n",
    "    join(dimension_ids_df.select('researcher_id'), on = 'researcher_id', how = 'inner').\\\n",
    "    withColumnRenamed('publication_id', 'citing_publication_id').\\\n",
    "    withColumnRenamed('researcher_id', 'citing_researcher_id').\\\n",
    "    join(citations.drop('citation_year'), on = 'citing_publication_id', how = 'inner').\\\n",
    "    join(authorship, on = 'publication_id', how = 'inner').\\\n",
    "    select('researcher_id', 'citing_researcher_id').\\\n",
    "    withColumnRenamed('researcher_id', 'related_researcher_id').\\\n",
    "    withColumnRenamed('citing_researcher_id', 'researcher_id').\\\n",
    "    dropDuplicates().toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_author_citing.to_csv('./data/potential_author_citing.csv', index = False)\n",
    "potential_author_referenced.to_csv('./data/potential_author_referenced.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([potential_author_citing, potential_author_referenced]).drop_duplicates().to_csv('./data/potential_author_bib.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_author_bib = pd.read_csv('./data/potential_author_bib.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43750730"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(potential_author_bib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
