{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lliang06/.local/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# import faiss\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from scipy.stats import entropy\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_researchers_profile = pd.read_csv('./data/target_researchers_profile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2name = {}\n",
    "for i in range(len(target_researchers_profile)):\n",
    "    id2name[target_researchers_profile.loc[i]['researcher_id']] = target_researchers_profile.loc[i]['PI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lda_pubid = pd.read_csv('./data/lda_pubid.csv')\n",
    "pubid = pd.read_csv('./data/lda_pubid.csv')\n",
    "pubid_year = pd.read_csv('./data/pubid_year.csv')\n",
    "pub2re = pd.read_parquet('./data/target_abstracts_pub2researcher.parquet')\n",
    "pub_cnt = pd.read_csv('./data/pub_count.csv')\n",
    "foa_abstracts = pd.read_csv('./data/energy_grants_Dimensions_wAbstract_cleanest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_author_citing = pd.read_csv('./data/potential_author_citing.csv')\n",
    "potential_author_referenced = pd.read_csv('./data/potential_author_referenced.csv')\n",
    "\n",
    "potential_author_citing['citing'] = len(potential_author_citing) * [1]\n",
    "potential_author_referenced['referenced'] = len(potential_author_referenced) * [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779943aa24a64e798d7d1477ede6ef82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=61.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "all_vec = np.load(open('./data/lda/d100/embedding/d100_66_lda_part' + str(j) + '.npy', 'rb'))\n",
    "for j in tqdm(range(1, 62)):\n",
    "    all_vec = np.vstack([all_vec, np.load(open('./data/lda/d100/embedding/d100_66_lda_part' + str(j) + '.npy', 'rb'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/lda/d100/FOA_d100_66.npy', 'rb') as f:\n",
    "    vec_foa = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6187432, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_foa_df = pd.DataFrame(vec_foa)\n",
    "vec_foa_df = vec_foa_df.set_index(pd.Index(foa_abstracts['Award_number'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_researcher = foa_abstracts[['Award_number', 'researcher_id']]\n",
    "\n",
    "grant2re = grant_researcher.set_index('Award_number').T.to_dict('records')[0]\n",
    "\n",
    "vec_df = pd.DataFrame(all_vec)\n",
    "\n",
    "vec_df = vec_df.set_index(pd.Index(pubid['publication_id'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_PI_idx = pd.read_csv('./data/all_PI_idx.csv')\n",
    "sampled_id = all_PI_idx[all_PI_idx['category'] != 'potential']['researcher_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad0656ade884e169dda466cdaeefc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=124.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "matching_dict = {}\n",
    "\n",
    "matching_dict['funded_name'] = []\n",
    "matching_dict['funded_id'] = []\n",
    "matching_dict['funded_npubs'] = []\n",
    "matching_dict['funded_entropy'] = []\n",
    "matching_dict['funded_FOA_similarity'] = []\n",
    "matching_dict['matched_name'] = []\n",
    "matching_dict['matched_id'] = []\n",
    "matching_dict['matched_cosine_similarity'] = []\n",
    "matching_dict['matched_npubs'] = []\n",
    "matching_dict['matched_entropy'] = []\n",
    "matching_dict['matched_FOA_similarity'] = []\n",
    "\n",
    "\n",
    "\n",
    "for target_rid in tqdm(sampled_id):\n",
    "    target_name = id2name[target_rid]\n",
    "    grant_years = foa_abstracts[foa_abstracts['researcher_id'] == target_rid]['StartYear'].values\n",
    "    if len(grant_years) != 0:\n",
    "        grant_year = grant_years[0]\n",
    "        Award_number = foa_abstracts[foa_abstracts['researcher_id'] == target_rid]['Award_number'].values[0]\n",
    "        Award_LDA = vec_foa_df.loc[Award_number].values\n",
    "\n",
    "        tmp_pub = pub2re[(pub2re['researcher_id'] == target_rid) & (pub2re['publication_id'].isin(pubid_year[(pubid_year['year'] < grant_year) & (pubid_year['year'] >= (grant_year - 10))]['publication_id'].values))]\n",
    "        target_pubcount = len(tmp_pub)\n",
    "        if target_pubcount >= 1:\n",
    "            tmp_pub = tmp_pub.set_index(pd.Index(tmp_pub['publication_id'].values.tolist())).drop(['publication_id'], axis = 1)\n",
    "\n",
    "            tmp_lda = vec_df.\\\n",
    "                join(tmp_pub, how = 'inner').drop(['researcher_id'], axis = 1)\n",
    "\n",
    "            target_lda = tmp_lda.mean(axis = 0).values\n",
    "            target_entropy = entropy(target_lda)\n",
    "\n",
    "            tmp_other_pub = pub2re[(pub2re['researcher_id'] != target_rid) & (pub2re['publication_id'].isin(pubid_year[(pubid_year['year'] < grant_year) & (pubid_year['year'] >= (grant_year - 10))]['publication_id'].values))]\n",
    "\n",
    "            other_researcher_count = tmp_other_pub.groupby('researcher_id').count().reset_index()\n",
    "            other_researcher_id = other_researcher_count[other_researcher_count['publication_id'] >= 10]['researcher_id'].values\n",
    "            other_researcher_pubcount = other_researcher_count[other_researcher_count['researcher_id'].isin(other_researcher_id)].reset_index(drop = True)\n",
    "            other_researcher_pubcount = other_researcher_pubcount.set_index(pd.Index(other_researcher_pubcount['researcher_id'].values.tolist())).drop(['researcher_id'], axis = 1)\n",
    "\n",
    "            tmp_other_pub = tmp_other_pub[tmp_other_pub['researcher_id'].isin(other_researcher_id)].reset_index(drop = True)\n",
    "\n",
    "            other_lda = vec_df.\\\n",
    "                reset_index().rename({'index': 'publication_id'}, axis = 1).\\\n",
    "                merge(tmp_other_pub, on = 'publication_id', how = 'inner').\\\n",
    "                drop(['publication_id'], axis = 1).groupby('researcher_id').mean()\n",
    "\n",
    "            other_rid = other_lda.index.tolist()\n",
    "            other_entropy = entropy(other_lda.values, axis = 1)\n",
    "            top_idx = np.argsort(cosine_similarity(target_lda.reshape(1, -1), other_lda.values))[0][-50:][::-1]\n",
    "            top_dist = cosine_similarity(target_lda.reshape(1, -1), other_lda.values)[0][top_idx]\n",
    "            top_rid = [other_rid[idx] for idx in top_idx]\n",
    "            top_name = [id2name[rid] for rid in top_rid]\n",
    "\n",
    "            top_entropy = [other_entropy[idx] for idx in top_idx]\n",
    "            top_pubcount = [other_researcher_pubcount.loc[rid]['publication_id'] for rid in top_rid]\n",
    "            top_lda = other_lda.loc[top_rid]\n",
    "\n",
    "            other_foa_dist = cosine_similarity(Award_LDA.reshape(1, -1), top_lda.values)\n",
    "\n",
    "            target_foa_dist = cosine_similarity(Award_LDA.reshape(1, -1), target_lda.reshape(1, -1))\n",
    "            \n",
    "            matching_dict['funded_name'] += [target_name] * len(top_name)\n",
    "            matching_dict['funded_id'] += [target_rid] * len(top_name)\n",
    "            matching_dict['funded_npubs'] += [target_pubcount] * len(top_name)\n",
    "            matching_dict['funded_entropy'] += [target_entropy] * len(top_name)\n",
    "            matching_dict['funded_FOA_similarity'] += [target_foa_dist[0][0]] * len(top_name)\n",
    "            matching_dict['matched_name'] += top_name\n",
    "            matching_dict['matched_id'] += top_rid\n",
    "            matching_dict['matched_cosine_similarity'] += top_dist.tolist()\n",
    "            matching_dict['matched_npubs'] += top_pubcount\n",
    "            matching_dict['matched_entropy'] += top_entropy\n",
    "            matching_dict['matched_FOA_similarity'] += other_foa_dist[0].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funded_name</th>\n",
       "      <th>funded_id</th>\n",
       "      <th>funded_npubs</th>\n",
       "      <th>funded_entropy</th>\n",
       "      <th>funded_FOA_similarity</th>\n",
       "      <th>matched_name</th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_cosine_similarity</th>\n",
       "      <th>matched_npubs</th>\n",
       "      <th>matched_entropy</th>\n",
       "      <th>matched_FOA_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>Emmanuel G Collins</td>\n",
       "      <td>ur.011471236145.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>Joydeep Acharya</td>\n",
       "      <td>ur.010701015017.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>Bren C Mochocki</td>\n",
       "      <td>ur.013765276155.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>Lei Wu</td>\n",
       "      <td>ur.010322327104.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.605145</td>\n",
       "      <td>0.999969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>Yu Ding</td>\n",
       "      <td>ur.015716633211.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>4.605148</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>Sean A Ramprashad</td>\n",
       "      <td>ur.010162606610.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>4.605143</td>\n",
       "      <td>0.999945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>Joydeep Acharya</td>\n",
       "      <td>ur.010701015017.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>4.605142</td>\n",
       "      <td>0.999951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>Kia Bazargan</td>\n",
       "      <td>ur.013344732015.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>4.605150</td>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>Haomiao Huang</td>\n",
       "      <td>ur.012561141107.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>4.605145</td>\n",
       "      <td>0.999947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>Beibei Wang</td>\n",
       "      <td>ur.016163775405.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>4.605145</td>\n",
       "      <td>0.999949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              funded_name           funded_id  funded_npubs  funded_entropy  \\\n",
       "0     Santiago C Grijalva  ur.013335016502.92            19        4.605146   \n",
       "1     Santiago C Grijalva  ur.013335016502.92            19        4.605146   \n",
       "2     Santiago C Grijalva  ur.013335016502.92            19        4.605146   \n",
       "3     Santiago C Grijalva  ur.013335016502.92            19        4.605146   \n",
       "4     Santiago C Grijalva  ur.013335016502.92            19        4.605146   \n",
       "...                   ...                 ...           ...             ...   \n",
       "5995           Zhi-Hua Qu  ur.016570352533.21           109        4.605146   \n",
       "5996           Zhi-Hua Qu  ur.016570352533.21           109        4.605146   \n",
       "5997           Zhi-Hua Qu  ur.016570352533.21           109        4.605146   \n",
       "5998           Zhi-Hua Qu  ur.016570352533.21           109        4.605146   \n",
       "5999           Zhi-Hua Qu  ur.016570352533.21           109        4.605146   \n",
       "\n",
       "      funded_FOA_similarity        matched_name          matched_id  \\\n",
       "0                  0.999973  Emmanuel G Collins  ur.011471236145.91   \n",
       "1                  0.999973     Joydeep Acharya  ur.010701015017.59   \n",
       "2                  0.999973     Bren C Mochocki  ur.013765276155.27   \n",
       "3                  0.999973              Lei Wu  ur.010322327104.06   \n",
       "4                  0.999973             Yu Ding  ur.015716633211.16   \n",
       "...                     ...                 ...                 ...   \n",
       "5995               0.999950   Sean A Ramprashad  ur.010162606610.47   \n",
       "5996               0.999950     Joydeep Acharya  ur.010701015017.59   \n",
       "5997               0.999950        Kia Bazargan  ur.013344732015.91   \n",
       "5998               0.999950       Haomiao Huang  ur.012561141107.08   \n",
       "5999               0.999950         Beibei Wang  ur.016163775405.92   \n",
       "\n",
       "      matched_cosine_similarity  matched_npubs  matched_entropy  \\\n",
       "0                           1.0             54         4.605146   \n",
       "1                           1.0             11         4.605147   \n",
       "2                           1.0             11         4.605147   \n",
       "3                           1.0             12         4.605145   \n",
       "4                           1.0             46         4.605148   \n",
       "...                         ...            ...              ...   \n",
       "5995                        1.0             37         4.605143   \n",
       "5996                        1.0             15         4.605142   \n",
       "5997                        1.0             38         4.605150   \n",
       "5998                        1.0             15         4.605145   \n",
       "5999                        1.0             34         4.605145   \n",
       "\n",
       "      matched_FOA_similarity  \n",
       "0                   0.999971  \n",
       "1                   0.999972  \n",
       "2                   0.999975  \n",
       "3                   0.999969  \n",
       "4                   0.999973  \n",
       "...                      ...  \n",
       "5995                0.999945  \n",
       "5996                0.999951  \n",
       "5997                0.999957  \n",
       "5998                0.999947  \n",
       "5999                0.999949  \n",
       "\n",
       "[6000 rows x 11 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(matching_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matching_dict).\\\n",
    "    merge(potential_author_citing.\\\n",
    "              rename({'researcher_id': 'funded_id', 'citing_researcher_id': 'matched_id'}, axis = 1),\n",
    "          on = ['funded_id', 'matched_id'], \n",
    "          how = 'left').\\\n",
    "    merge(potential_author_referenced.\\\n",
    "              rename({'researcher_id': 'funded_id', 'referenced_researcher_id': 'matched_id'}, axis = 1),\n",
    "          on = ['funded_id', 'matched_id'], \n",
    "          how = 'left').\\\n",
    "    fillna(0).to_csv('./data/matching_foa_researcher_124_d100_66.csv', index = False)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthorship_weight = pd.read_csv('./data/pubid_coauthor_count.csv')\n",
    "coauthorship_weight = coauthorship_weight.set_index(coauthorship_weight['publication_id']).drop(['publication_id'], axis = 1)\n",
    "weighted_vec = coauthorship_weight.join(vec_df)\n",
    "weighted_vec = weighted_vec.iloc[:, :].div(weighted_vec.coauthor_count, axis=0)\n",
    "weighted_vec = weighted_vec.drop('coauthor_count', axis = 1)\n",
    "coauthorship_weight['weight'] = coauthorship_weight['coauthor_count'].apply(lambda x: 1 / x)\n",
    "coauthorship_weight = pd.read_csv('./data/pubid_coauthor_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a9783c788a49e5a3486cc67e5bae1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=124.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "matching_dict = {}\n",
    "\n",
    "matching_dict['funded_name'] = []\n",
    "matching_dict['funded_id'] = []\n",
    "matching_dict['funded_npubs'] = []\n",
    "matching_dict['funded_entropy'] = []\n",
    "matching_dict['funded_FOA_similarity'] = []\n",
    "matching_dict['matched_name'] = []\n",
    "matching_dict['matched_id'] = []\n",
    "matching_dict['matched_cosine_similarity'] = []\n",
    "matching_dict['matched_npubs'] = []\n",
    "matching_dict['matched_entropy'] = []\n",
    "matching_dict['matched_FOA_similarity'] = []\n",
    "\n",
    "\n",
    "\n",
    "for target_rid in tqdm(sampled_id):\n",
    "    target_name = id2name[target_rid]\n",
    "    grant_years = foa_abstracts[foa_abstracts['researcher_id'] == target_rid]['StartYear'].values\n",
    "    if len(grant_years) != 0:\n",
    "        grant_year = grant_years[0]\n",
    "        Award_number = foa_abstracts[foa_abstracts['researcher_id'] == target_rid]['Award_number'].values[0]\n",
    "        Award_LDA = vec_foa_df.loc[Award_number].values\n",
    "\n",
    "        tmp_pub = pub2re[(pub2re['researcher_id'] == target_rid) & (pub2re['publication_id'].isin(pubid_year[(pubid_year['year'] < grant_year) & (pubid_year['year'] >= (grant_year - 10))]['publication_id'].values))]\n",
    "        target_pubcount = len(tmp_pub)\n",
    "        if target_pubcount >= 1:\n",
    "            tmp_pub = tmp_pub.set_index(pd.Index(tmp_pub['publication_id'].values.tolist())).drop(['publication_id'], axis = 1)\n",
    "\n",
    "            tmp_lda = weighted_vec.\\\n",
    "                join(tmp_pub, how = 'inner').drop(['researcher_id'], axis = 1)\n",
    "\n",
    "            target_lda = tmp_lda.mean(axis = 0).values\n",
    "            target_entropy = entropy(target_lda)\n",
    "\n",
    "            tmp_other_pub = pub2re[(pub2re['researcher_id'] != target_rid) & (pub2re['publication_id'].isin(pubid_year[(pubid_year['year'] < grant_year) & (pubid_year['year'] >= (grant_year - 10))]['publication_id'].values))]\n",
    "\n",
    "            other_researcher_count = tmp_other_pub.groupby('researcher_id').count().reset_index()\n",
    "            other_researcher_id = other_researcher_count[other_researcher_count['publication_id'] >= 10]['researcher_id'].values\n",
    "            other_researcher_pubcount = other_researcher_count[other_researcher_count['researcher_id'].isin(other_researcher_id)].reset_index(drop = True)\n",
    "            other_researcher_pubcount = other_researcher_pubcount.set_index(pd.Index(other_researcher_pubcount['researcher_id'].values.tolist())).drop(['researcher_id'], axis = 1)\n",
    "\n",
    "            tmp_other_pub = tmp_other_pub[tmp_other_pub['researcher_id'].isin(other_researcher_id)].reset_index(drop = True)\n",
    "\n",
    "            other_lda = weighted_vec.\\\n",
    "                reset_index().rename({'index': 'publication_id'}, axis = 1).\\\n",
    "                merge(tmp_other_pub, on = 'publication_id', how = 'inner').\\\n",
    "                drop(['publication_id'], axis = 1).groupby('researcher_id').mean()\n",
    "\n",
    "            other_rid = other_lda.index.tolist()\n",
    "            other_entropy = entropy(other_lda.values, axis = 1)\n",
    "            top_idx = np.argsort(cosine_similarity(target_lda.reshape(1, -1), other_lda.values))[0][-100:][::-1]\n",
    "            top_dist = cosine_similarity(target_lda.reshape(1, -1), other_lda.values)[0][top_idx]\n",
    "            top_rid = [other_rid[idx] for idx in top_idx]\n",
    "            top_name = [id2name[rid] for rid in top_rid]\n",
    "\n",
    "            top_entropy = [other_entropy[idx] for idx in top_idx]\n",
    "            top_pubcount = [other_researcher_pubcount.loc[rid]['publication_id'] for rid in top_rid]\n",
    "            top_lda = other_lda.loc[top_rid]\n",
    "\n",
    "            other_foa_dist = cosine_similarity(Award_LDA.reshape(1, -1), top_lda.values)\n",
    "\n",
    "            target_foa_dist = cosine_similarity(Award_LDA.reshape(1, -1), target_lda.reshape(1, -1))\n",
    "            \n",
    "            matching_dict['funded_name'] += [target_name] * len(top_name)\n",
    "            matching_dict['funded_id'] += [target_rid] * len(top_name)\n",
    "            matching_dict['funded_npubs'] += [target_pubcount] * len(top_name)\n",
    "            matching_dict['funded_entropy'] += [target_entropy] * len(top_name)\n",
    "            matching_dict['funded_FOA_similarity'] += [target_foa_dist[0][0]] * len(top_name)\n",
    "            matching_dict['matched_name'] += top_name\n",
    "            matching_dict['matched_id'] += top_rid\n",
    "            matching_dict['matched_cosine_similarity'] += top_dist.tolist()\n",
    "            matching_dict['matched_npubs'] += top_pubcount\n",
    "            matching_dict['matched_entropy'] += top_entropy\n",
    "            matching_dict['matched_FOA_similarity'] += other_foa_dist[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funded_name</th>\n",
       "      <th>funded_id</th>\n",
       "      <th>funded_npubs</th>\n",
       "      <th>funded_entropy</th>\n",
       "      <th>funded_FOA_similarity</th>\n",
       "      <th>matched_name</th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_cosine_similarity</th>\n",
       "      <th>matched_npubs</th>\n",
       "      <th>matched_entropy</th>\n",
       "      <th>matched_FOA_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>Jorge F Valenzuela</td>\n",
       "      <td>ur.012106654411.32</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>4.605148</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>Chunting Mi</td>\n",
       "      <td>ur.011434721140.49</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>Daji Qiao</td>\n",
       "      <td>ur.07611240351.64</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>Girish Vinayak Chowdhary</td>\n",
       "      <td>ur.016663530513.65</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>4.605146</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Santiago C Grijalva</td>\n",
       "      <td>ur.013335016502.92</td>\n",
       "      <td>19</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>Ilya V Kolmanovsky</td>\n",
       "      <td>ur.016131577413.61</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>143</td>\n",
       "      <td>4.605149</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605145</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>Jack D Reilly</td>\n",
       "      <td>ur.012423357433.35</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>12</td>\n",
       "      <td>4.605139</td>\n",
       "      <td>0.999937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605145</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>John J Hasenbein</td>\n",
       "      <td>ur.013040047235.99</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>21</td>\n",
       "      <td>4.605147</td>\n",
       "      <td>0.999941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605145</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>Leonardo Bobadilla</td>\n",
       "      <td>ur.013073650035.26</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>11</td>\n",
       "      <td>4.605143</td>\n",
       "      <td>0.999938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605145</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>Nathan Wayne Fisher</td>\n",
       "      <td>ur.013125433747.65</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>50</td>\n",
       "      <td>4.605142</td>\n",
       "      <td>0.999937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>Zhi-Hua Qu</td>\n",
       "      <td>ur.016570352533.21</td>\n",
       "      <td>109</td>\n",
       "      <td>4.605145</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>Taehyun Shim</td>\n",
       "      <td>ur.015274562733.47</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>35</td>\n",
       "      <td>4.605149</td>\n",
       "      <td>0.999942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               funded_name           funded_id  funded_npubs  funded_entropy  \\\n",
       "0      Santiago C Grijalva  ur.013335016502.92            19        4.605147   \n",
       "1      Santiago C Grijalva  ur.013335016502.92            19        4.605147   \n",
       "2      Santiago C Grijalva  ur.013335016502.92            19        4.605147   \n",
       "3      Santiago C Grijalva  ur.013335016502.92            19        4.605147   \n",
       "4      Santiago C Grijalva  ur.013335016502.92            19        4.605147   \n",
       "...                    ...                 ...           ...             ...   \n",
       "11995           Zhi-Hua Qu  ur.016570352533.21           109        4.605145   \n",
       "11996           Zhi-Hua Qu  ur.016570352533.21           109        4.605145   \n",
       "11997           Zhi-Hua Qu  ur.016570352533.21           109        4.605145   \n",
       "11998           Zhi-Hua Qu  ur.016570352533.21           109        4.605145   \n",
       "11999           Zhi-Hua Qu  ur.016570352533.21           109        4.605145   \n",
       "\n",
       "       funded_FOA_similarity              matched_name          matched_id  \\\n",
       "0                   0.999975        Jorge F Valenzuela  ur.012106654411.32   \n",
       "1                   0.999975               Chunting Mi  ur.011434721140.49   \n",
       "2                   0.999975                 Daji Qiao   ur.07611240351.64   \n",
       "3                   0.999975  Girish Vinayak Chowdhary  ur.016663530513.65   \n",
       "4                   0.999975        Ilya V Kolmanovsky  ur.016131577413.61   \n",
       "...                      ...                       ...                 ...   \n",
       "11995               0.999944             Jack D Reilly  ur.012423357433.35   \n",
       "11996               0.999944          John J Hasenbein  ur.013040047235.99   \n",
       "11997               0.999944        Leonardo Bobadilla  ur.013073650035.26   \n",
       "11998               0.999944       Nathan Wayne Fisher  ur.013125433747.65   \n",
       "11999               0.999944              Taehyun Shim  ur.015274562733.47   \n",
       "\n",
       "       matched_cosine_similarity  matched_npubs  matched_entropy  \\\n",
       "0                       1.000000             22         4.605148   \n",
       "1                       1.000000             13         4.605147   \n",
       "2                       1.000000             52         4.605147   \n",
       "3                       1.000000             13         4.605146   \n",
       "4                       1.000000            143         4.605149   \n",
       "...                          ...            ...              ...   \n",
       "11995                   0.999999             12         4.605139   \n",
       "11996                   0.999999             21         4.605147   \n",
       "11997                   0.999999             11         4.605143   \n",
       "11998                   0.999999             50         4.605142   \n",
       "11999                   0.999999             35         4.605149   \n",
       "\n",
       "       matched_FOA_similarity  \n",
       "0                    0.999975  \n",
       "1                    0.999975  \n",
       "2                    0.999974  \n",
       "3                    0.999977  \n",
       "4                    0.999973  \n",
       "...                       ...  \n",
       "11995                0.999937  \n",
       "11996                0.999941  \n",
       "11997                0.999938  \n",
       "11998                0.999937  \n",
       "11999                0.999942  \n",
       "\n",
       "[12000 rows x 11 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(matching_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matching_dict).\\\n",
    "    merge(potential_author_citing.\\\n",
    "              rename({'researcher_id': 'funded_id', 'citing_researcher_id': 'matched_id'}, axis = 1),\n",
    "          on = ['funded_id', 'matched_id'], \n",
    "          how = 'left').\\\n",
    "    merge(potential_author_referenced.\\\n",
    "              rename({'researcher_id': 'funded_id', 'referenced_researcher_id': 'matched_id'}, axis = 1),\n",
    "          on = ['funded_id', 'matched_id'], \n",
    "          how = 'left').\\\n",
    "    fillna(0).to_csv('./data/matching_foa_researcher_124_d100_66_weighted.csv', index = False)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9132741399a4425285a4635fe343d587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=61.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = 0\n",
    "all_vec = np.load(open('./data/lda/d100/embedding_default/d100_lda_part' + str(j) + '.npy', 'rb'))\n",
    "for j in tqdm(range(1, 62)):\n",
    "    all_vec = np.vstack([all_vec, np.load(open('./data/lda/d100/embedding_default/d100_lda_part' + str(j) + '.npy', 'rb'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dict = {}\n",
    "\n",
    "matching_dict['funded_name'] = []\n",
    "matching_dict['funded_id'] = []\n",
    "matching_dict['funded_npubs'] = []\n",
    "matching_dict['funded_entropy'] = []\n",
    "matching_dict['funded_FOA_similarity'] = []\n",
    "matching_dict['matched_name'] = []\n",
    "matching_dict['matched_id'] = []\n",
    "matching_dict['matched_cosine_similarity'] = []\n",
    "matching_dict['matched_npubs'] = []\n",
    "matching_dict['matched_entropy'] = []\n",
    "matching_dict['matched_FOA_similarity'] = []\n",
    "\n",
    "\n",
    "\n",
    "for target_rid in tqdm(sampled_id):\n",
    "    target_name = id2name[target_rid]\n",
    "    grant_years = foa_abstracts[foa_abstracts['researcher_id'] == target_rid]['StartYear'].values\n",
    "    if len(grant_years) != 0:\n",
    "        grant_year = grant_years[0]\n",
    "        Award_number = foa_abstracts[foa_abstracts['researcher_id'] == target_rid]['Award_number'].values[0]\n",
    "        Award_LDA = vec_foa_df.loc[Award_number].values\n",
    "\n",
    "        tmp_pub = pub2re[(pub2re['researcher_id'] == target_rid) & (pub2re['publication_id'].isin(pubid_year[(pubid_year['year'] < grant_year) & (pubid_year['year'] >= (grant_year - 10))]['publication_id'].values))]\n",
    "        target_pubcount = len(tmp_pub)\n",
    "        if target_pubcount >= 1:\n",
    "            tmp_pub = tmp_pub.set_index(pd.Index(tmp_pub['publication_id'].values.tolist())).drop(['publication_id'], axis = 1)\n",
    "\n",
    "            tmp_lda = vec_df.\\\n",
    "                join(tmp_pub, how = 'inner').drop(['researcher_id'], axis = 1)\n",
    "\n",
    "            target_lda = tmp_lda.mean(axis = 0).values\n",
    "            target_entropy = entropy(target_lda)\n",
    "\n",
    "            tmp_other_pub = pub2re[(pub2re['researcher_id'] != target_rid) & (pub2re['publication_id'].isin(pubid_year[(pubid_year['year'] < grant_year) & (pubid_year['year'] >= (grant_year - 10))]['publication_id'].values))]\n",
    "\n",
    "            other_researcher_count = tmp_other_pub.groupby('researcher_id').count().reset_index()\n",
    "            other_researcher_id = other_researcher_count[other_researcher_count['publication_id'] >= 10]['researcher_id'].values\n",
    "            other_researcher_pubcount = other_researcher_count[other_researcher_count['researcher_id'].isin(other_researcher_id)].reset_index(drop = True)\n",
    "            other_researcher_pubcount = other_researcher_pubcount.set_index(pd.Index(other_researcher_pubcount['researcher_id'].values.tolist())).drop(['researcher_id'], axis = 1)\n",
    "\n",
    "            tmp_other_pub = tmp_other_pub[tmp_other_pub['researcher_id'].isin(other_researcher_id)].reset_index(drop = True)\n",
    "\n",
    "            other_lda = vec_df.\\\n",
    "                reset_index().rename({'index': 'publication_id'}, axis = 1).\\\n",
    "                merge(tmp_other_pub, on = 'publication_id', how = 'inner').\\\n",
    "                drop(['publication_id'], axis = 1).groupby('researcher_id').mean()\n",
    "\n",
    "            other_rid = other_lda.index.tolist()\n",
    "            other_entropy = entropy(other_lda.values, axis = 1)\n",
    "            top_idx = np.argsort(cosine_similarity(target_lda.reshape(1, -1), other_lda.values))[0][-50:][::-1]\n",
    "            top_dist = cosine_similarity(target_lda.reshape(1, -1), other_lda.values)[0][top_idx]\n",
    "            top_rid = [other_rid[idx] for idx in top_idx]\n",
    "            top_name = [id2name[rid] for rid in top_rid]\n",
    "\n",
    "            top_entropy = [other_entropy[idx] for idx in top_idx]\n",
    "            top_pubcount = [other_researcher_pubcount.loc[rid]['publication_id'] for rid in top_rid]\n",
    "            top_lda = other_lda.loc[top_rid]\n",
    "\n",
    "            other_foa_dist = cosine_similarity(Award_LDA.reshape(1, -1), top_lda.values)\n",
    "\n",
    "            target_foa_dist = cosine_similarity(Award_LDA.reshape(1, -1), target_lda.reshape(1, -1))\n",
    "            \n",
    "            matching_dict['funded_name'] += [target_name] * len(top_name)\n",
    "            matching_dict['funded_id'] += [target_rid] * len(top_name)\n",
    "            matching_dict['funded_npubs'] += [target_pubcount] * len(top_name)\n",
    "            matching_dict['funded_entropy'] += [target_entropy] * len(top_name)\n",
    "            matching_dict['funded_FOA_similarity'] += [target_foa_dist[0][0]] * len(top_name)\n",
    "            matching_dict['matched_name'] += top_name\n",
    "            matching_dict['matched_id'] += top_rid\n",
    "            matching_dict['matched_cosine_similarity'] += top_dist.tolist()\n",
    "            matching_dict['matched_npubs'] += top_pubcount\n",
    "            matching_dict['matched_entropy'] += top_entropy\n",
    "            matching_dict['matched_FOA_similarity'] += other_foa_dist[0].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matching_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matching_dict).\\\n",
    "    merge(potential_author_citing.\\\n",
    "              rename({'researcher_id': 'funded_id', 'citing_researcher_id': 'matched_id'}, axis = 1),\n",
    "          on = ['funded_id', 'matched_id'], \n",
    "          how = 'left').\\\n",
    "    merge(potential_author_referenced.\\\n",
    "              rename({'researcher_id': 'funded_id', 'referenced_researcher_id': 'matched_id'}, axis = 1),\n",
    "          on = ['funded_id', 'matched_id'], \n",
    "          how = 'left').\\\n",
    "    fillna(0).to_csv('./data/matching_foa_researcher_124_d100_default.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dict = {}\n",
    "\n",
    "matching_dict['funded_name'] = []\n",
    "matching_dict['funded_id'] = []\n",
    "matching_dict['funded_npubs'] = []\n",
    "matching_dict['funded_entropy'] = []\n",
    "matching_dict['funded_FOA_similarity'] = []\n",
    "matching_dict['matched_name'] = []\n",
    "matching_dict['matched_id'] = []\n",
    "matching_dict['matched_cosine_similarity'] = []\n",
    "matching_dict['matched_npubs'] = []\n",
    "matching_dict['matched_entropy'] = []\n",
    "matching_dict['matched_FOA_similarity'] = []\n",
    "\n",
    "\n",
    "\n",
    "for target_rid in tqdm(sampled_id):\n",
    "    target_name = id2name[target_rid]\n",
    "    grant_years = foa_abstracts[foa_abstracts['researcher_id'] == target_rid]['StartYear'].values\n",
    "    if len(grant_years) != 0:\n",
    "        grant_year = grant_years[0]\n",
    "        Award_number = foa_abstracts[foa_abstracts['researcher_id'] == target_rid]['Award_number'].values[0]\n",
    "        Award_LDA = vec_foa_df.loc[Award_number].values\n",
    "\n",
    "        tmp_pub = pub2re[(pub2re['researcher_id'] == target_rid) & (pub2re['publication_id'].isin(pubid_year[(pubid_year['year'] < grant_year) & (pubid_year['year'] >= (grant_year - 10))]['publication_id'].values))]\n",
    "        target_pubcount = len(tmp_pub)\n",
    "        if target_pubcount >= 1:\n",
    "            tmp_pub = tmp_pub.set_index(pd.Index(tmp_pub['publication_id'].values.tolist())).drop(['publication_id'], axis = 1)\n",
    "\n",
    "            tmp_lda = weighted_vec.\\\n",
    "                join(tmp_pub, how = 'inner').drop(['researcher_id'], axis = 1)\n",
    "\n",
    "            target_lda = tmp_lda.mean(axis = 0).values\n",
    "            target_entropy = entropy(target_lda)\n",
    "\n",
    "            tmp_other_pub = pub2re[(pub2re['researcher_id'] != target_rid) & (pub2re['publication_id'].isin(pubid_year[(pubid_year['year'] < grant_year) & (pubid_year['year'] >= (grant_year - 10))]['publication_id'].values))]\n",
    "\n",
    "            other_researcher_count = tmp_other_pub.groupby('researcher_id').count().reset_index()\n",
    "            other_researcher_id = other_researcher_count[other_researcher_count['publication_id'] >= 10]['researcher_id'].values\n",
    "            other_researcher_pubcount = other_researcher_count[other_researcher_count['researcher_id'].isin(other_researcher_id)].reset_index(drop = True)\n",
    "            other_researcher_pubcount = other_researcher_pubcount.set_index(pd.Index(other_researcher_pubcount['researcher_id'].values.tolist())).drop(['researcher_id'], axis = 1)\n",
    "\n",
    "            tmp_other_pub = tmp_other_pub[tmp_other_pub['researcher_id'].isin(other_researcher_id)].reset_index(drop = True)\n",
    "\n",
    "            other_lda = weighted_vec.\\\n",
    "                reset_index().rename({'index': 'publication_id'}, axis = 1).\\\n",
    "                merge(tmp_other_pub, on = 'publication_id', how = 'inner').\\\n",
    "                drop(['publication_id'], axis = 1).groupby('researcher_id').mean()\n",
    "\n",
    "            other_rid = other_lda.index.tolist()\n",
    "            other_entropy = entropy(other_lda.values, axis = 1)\n",
    "            top_idx = np.argsort(cosine_similarity(target_lda.reshape(1, -1), other_lda.values))[0][-100:][::-1]\n",
    "            top_dist = cosine_similarity(target_lda.reshape(1, -1), other_lda.values)[0][top_idx]\n",
    "            top_rid = [other_rid[idx] for idx in top_idx]\n",
    "            top_name = [id2name[rid] for rid in top_rid]\n",
    "\n",
    "            top_entropy = [other_entropy[idx] for idx in top_idx]\n",
    "            top_pubcount = [other_researcher_pubcount.loc[rid]['publication_id'] for rid in top_rid]\n",
    "            top_lda = other_lda.loc[top_rid]\n",
    "\n",
    "            other_foa_dist = cosine_similarity(Award_LDA.reshape(1, -1), top_lda.values)\n",
    "\n",
    "            target_foa_dist = cosine_similarity(Award_LDA.reshape(1, -1), target_lda.reshape(1, -1))\n",
    "            \n",
    "            matching_dict['funded_name'] += [target_name] * len(top_name)\n",
    "            matching_dict['funded_id'] += [target_rid] * len(top_name)\n",
    "            matching_dict['funded_npubs'] += [target_pubcount] * len(top_name)\n",
    "            matching_dict['funded_entropy'] += [target_entropy] * len(top_name)\n",
    "            matching_dict['funded_FOA_similarity'] += [target_foa_dist[0][0]] * len(top_name)\n",
    "            matching_dict['matched_name'] += top_name\n",
    "            matching_dict['matched_id'] += top_rid\n",
    "            matching_dict['matched_cosine_similarity'] += top_dist.tolist()\n",
    "            matching_dict['matched_npubs'] += top_pubcount\n",
    "            matching_dict['matched_entropy'] += top_entropy\n",
    "            matching_dict['matched_FOA_similarity'] += other_foa_dist[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matching_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matching_dict).\\\n",
    "    merge(potential_author_citing.\\\n",
    "              rename({'researcher_id': 'funded_id', 'citing_researcher_id': 'matched_id'}, axis = 1),\n",
    "          on = ['funded_id', 'matched_id'], \n",
    "          how = 'left').\\\n",
    "    merge(potential_author_referenced.\\\n",
    "              rename({'researcher_id': 'funded_id', 'referenced_researcher_id': 'matched_id'}, axis = 1),\n",
    "          on = ['funded_id', 'matched_id'], \n",
    "          how = 'left').\\\n",
    "    fillna(0).to_csv('./data/matching_foa_researcher_124_d100_default_weighted.csv', index = False)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
